{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 - IO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: David Henning (worked with Natasha Watkins, Chandni Raja and Jonathan Kowarski)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.api import OLS, tsa\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"PS1_Data/OTC_Data.csv\", sep='\\t')\n",
    "#d[d.duplicated(subset=['store', 'week', 'brand'], keep=False)] # No duplicates at store-week-brand level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_demographic = pd.read_csv(\"PS1_Data/OTCDemographics.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.sort_values(by=['store', 'week', 'brand'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to reproduce summary stat table from the problem set\n",
    "d['revenue'] = d['sales_'] * d['price_']\n",
    "d['revenue_brand'] = d.groupby(['brand'])['revenue'].transform('sum')\n",
    "d['sales_brand'] = d.groupby(['brand'])['sales_'].transform('sum')\n",
    "d['price_brand'] = d.groupby(['brand'])['price_'].transform('mean')\n",
    "d['cost_brand'] = d.groupby(['brand'])['cost_'].transform('mean')\n",
    "d['branded'] = d['brand']\n",
    "d.loc[d['branded'] <= 9, 'branded'] = 1\n",
    "d.loc[d['branded'] > 9, 'branded'] = 0\n",
    "d_summary = d[['brand', 'revenue_brand', 'sales_brand', 'price_brand', 'cost_brand']]\n",
    "d_summary = d_summary[:11]\n",
    "d_summary['revenue_tot'] = d_summary['revenue_brand'].sum()\n",
    "d_summary['share'] = d_summary['revenue_brand'] / d_summary['revenue_tot'] * 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_instruments = pd.read_csv(\"PS1_Data/OTCDataInstruments.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider utility function for good $j$ in store-week $t$ for consumer $i$:\n",
    "    $$ u_{ijt} = X_{jt}\\beta + \\alpha p_{jt} + \\xi_{jt} + \\epsilon_{jt} $$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (1) Estimate this model using OLS with price and promotion as product characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-2521c2f842fd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sales_store_week'] = df.groupby(['store', 'week'])['sales_'].transform('sum')\n",
      "<ipython-input-7-2521c2f842fd>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['s'] = df['sales_'] / df['sales_store_week'] * 0.62 # All of the brands have a total market share of 62%\n"
     ]
    }
   ],
   "source": [
    "# calculate the shares\n",
    "df = d[['store', 'week', 'brand', 'prom_', 'price_', 'cost_', 'sales_']]\n",
    "df['sales_store_week'] = df.groupby(['store', 'week'])['sales_'].transform('sum')\n",
    "df['s'] = df['sales_'] / df['sales_store_week'] * 0.62 # All of the brands have a total market share of 62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1cb6825e2c25>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['δ'] = np.log(df['s']) - np.log(s_0)\n",
      "<ipython-input-8-1cb6825e2c25>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['constant'] = 1\n"
     ]
    }
   ],
   "source": [
    "# Transform variables for regression, recall outside options share is 0.38\n",
    "s_0 = 0.38\n",
    "df['δ'] = np.log(df['s']) - np.log(s_0)\n",
    "df['constant'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OLS regression\n",
    "x = df.drop(['δ', 'store', 'week', 'brand',  'cost_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df['δ']\n",
    "results1 = OLS(y, x).fit()\n",
    "model1_α = results1.params['price_']\n",
    "#print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (2) Estimate this model using OLS with price and promotion as product characteristics and brand dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add dummies to dataframe\n",
    "b_dummies = pd.get_dummies(df['brand'])\n",
    "df_dummies = df.merge(b_dummies, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_dummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df_dummies['δ']\n",
    "results2 = OLS(y, x).fit()\n",
    "model2_α = results2.params['price_']\n",
    "#print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (3) Estimate this model using OLS with price and promotion as product characteristics and store-brand dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_brand = df['store'].astype('str') + '_' + df['brand'].astype('str') \n",
    "bs_dummies = pd.get_dummies(store_brand)\n",
    "df_bsdummies = df.merge(bs_dummies, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_bsdummies.drop(['δ', 'store', 's', 'brand', 'week', 'cost_', 'sales_', 'sales_store_week'], 1)\n",
    "y = df_bsdummies['δ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = OLS(y, x).fit()\n",
    "model3_α = results3.params['price_']\n",
    "#print(results3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (4) Estimate the models of 1, 2 and 3 using wholesale cost as an instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IV regression for first problem\n",
    "x = df.drop(['δ', 'store', 'week', 'brand',  'cost_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df.drop(['δ', 'store', 'week', 'brand', 'sales_', 'price_', 'sales_store_week', 's',], 1)\n",
    "y = df['δ']\n",
    "results4 = IV2SLS(y, x, instrument=z).fit()\n",
    "#print(results4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IV regression for second problem\n",
    "x = df_dummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df_dummies.drop(['δ', 'store', 'week', 'brand', 'sales_', 'price_', 'sales_store_week', 's',], 1)\n",
    "y = df['δ']\n",
    "results4 = IV2SLS(y, x, z).fit()\n",
    "#print(results4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IV regression for third problem\n",
    "x = df_bsdummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df_bsdummies.drop(['δ', 'store', 'week', 'brand', 'price_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df['δ']\n",
    "results4 = IV2SLS(y, x, z).fit()\n",
    "#print(results4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (5) Estimate the models of 1, 2 and 3 using the Hausman instrument (average price in other markets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3314831a76a0>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['price_iv'] = (mean*n - df['price_'])/(n-1)\n",
      "<ipython-input-18-3314831a76a0>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=['brand', 'week', 'store'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Calculate hausman instrument, and add to all the datasets\n",
    "grouped = df.groupby(['brand', 'week'])\n",
    "n = grouped['price_'].transform('count')\n",
    "mean = grouped['price_'].transform('mean')\n",
    "df['price_iv'] = (mean*n - df['price_'])/(n-1)\n",
    "df_dummies['price_iv'] = (mean*n - df['price_'])/(n-1)\n",
    "df_bsdummies['price_iv'] = (mean*n - df['price_'])/(n-1)\n",
    "df.sort_values(by=['brand', 'week', 'store'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the IV with  the Hausman instrument for (1)\n",
    "x = df.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_iv', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df['δ']\n",
    "results5 = IV2SLS(y, x, z).fit()\n",
    "#print(results5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the IV with  the Hausman instrument for (2)\n",
    "x = df_dummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_iv', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df_dummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df_dummies['δ']\n",
    "results5 = IV2SLS(y, x, z).fit()\n",
    "#print(results5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the IV with  the Hausman instrument for (3)\n",
    "x = df_bsdummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_iv', 'sales_', 'sales_store_week', 's',], 1)\n",
    "z = df_bsdummies.drop(['δ', 'store', 'week', 'brand',  'cost_', 'price_', 'sales_', 'sales_store_week', 's',], 1)\n",
    "y = df_bsdummies['δ']\n",
    "results5 = IV2SLS(y, x, z).fit()\n",
    "#print(results5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (6) Using the analytic formula for elasticity of the logit model, compute the mean own-price elasticities for all brand in the market using the estimates in 1, 2 and 3. Do these results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_summary['model1_η'] = -model1_α * d_summary['price_brand'] * (1 - d_summary['share'])\n",
    "d_summary['model2_η'] = -model2_α * d_summary['price_brand'] * (1 - d_summary['share'])\n",
    "d_summary['model3_η'] = -model3_α * d_summary['price_brand'] * (1 - d_summary['share'])\n",
    "#d_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider utility function for good $j$ in store-week $t$ for consumer $i$:\n",
    "    $$ u_{ijt} = X_{jt}\\beta + \\beta_{ib}B_{jt}\\text{(Branded Product)} + \\alpha_i p_{jt} + \\xi_{jt} + \\epsilon_{ijt} $$\n",
    "Where:\n",
    "$$\\beta_{ib} = \\sigma_B\\nu_i$$\n",
    "$$\\alpha_i = \\alpha + \\sigma_I I_i$$\n",
    "\n",
    "Hence $$ u_{ijt} = X_{jt}\\beta + \\sigma_B\\nu_iB_{jt}\\text{(Branded Product)} + (\\alpha + \\sigma_I I_i) p_{jt} + \\xi_{jt} + \\epsilon_{ijt} $$\n",
    "\n",
    "Or, rearranging $$ u_{ijt} = X_{jt}\\beta + \\alpha p_{jt} + \\xi_{jt} + \\sigma_B\\nu_iB_{jt}\\text{(Branded Product)} + \\sigma_I I_i p_{jt} + \\epsilon_{ijt} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_blp = pd.merge(d, d_demographic)\n",
    "d_blp['constant'] = 1\n",
    "d_blp['sales_store_week'] = d_blp.groupby(['store', 'week'])['sales_'].transform('sum')\n",
    "d_blp['s'] = d_blp['sales_'] / d_blp['sales_store_week'] * 0.62 # All of the brands have a total market share of 62%\n",
    "s = d_blp['sales_'] / d_blp['sales_store_week'] * 0.62 # All of the brands have a total market share of 62%\n",
    "\n",
    "#Put everything into arrays\n",
    "X = d_blp['constant'] \n",
    "p = d_blp['price_']\n",
    "B = d_blp['branded']\n",
    "I = d_blp.iloc[:, d_blp.columns.str.startswith('hhincome')]\n",
    "\n",
    "#Setting the frequencies\n",
    "ns = I.shape[1]\n",
    "\n",
    "#Starting values for parameters\n",
    "np.random.seed(1)\n",
    "v = np.random.normal(scale=1, size=ns) \n",
    "β = 0\n",
    "α = 0\n",
    "σ_B = 0.01\n",
    "σ_I = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate predicted shares\n",
    "#d_blp['δ'] = β * d_blp['constant'] + α * d_blp['price_']\n",
    "δ = β * d_blp['constant'] + α * d_blp['price_']\n",
    "s_hat = np.zeros(I.shape[0])\n",
    "for i in range(ns):\n",
    "    d_blp['numerator'] = np.exp(δ + σ_B * v[i] * d_blp['branded'] + σ_I * d_blp['hhincome' + str(i+1)] * d_blp['price_'])\n",
    "    denominator =  d_blp.groupby(['store', 'week'])['numerator'].transform('sum') + 1\n",
    "    #numerator = d_blp['numerator'] \n",
    "    s_hat += d_blp.numerator / denominator * (1 / ns)\n",
    "    \n",
    "    δ_new = δ + np.log(s) - np.log(s_hat)\n",
    "    dist = sum((δ - δ_new)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_blp_price = d_blp.pivot_table(index=[\"week\", \"brand\"], \n",
    "                    columns='store', \n",
    "                    values='price_')\n",
    "d_blp_price_f = d_blp_price.iloc[:,1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = d_blp[['week', 'brand', 'cost_']]\n",
    "z = z.merge(d_blp_price_f, on=['week', 'brand'])\n",
    "Z = z.drop(['week', 'brand'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_shares(α, β, σ_B, σ_I, δ, v, p, B, I, X):\n",
    "    max_iter = 100\n",
    "    dist = 10e3      # Initial distance\n",
    "    tol = 10e-10      # Tolerance\n",
    "    i = 0\n",
    "\n",
    "    while i < max_iter and dist > tol:\n",
    "        s_hat = np.zeros(I.shape[0])\n",
    "        \n",
    "        for i in range(ns):\n",
    "            d_blp['numerator'] = np.exp(δ + σ_B * v[i] * B + σ_I * I.iloc[:,i] * p)\n",
    "            denominator =  d_blp.groupby(['store', 'week'])['numerator'].transform('sum') + 1\n",
    "            s_hat += d_blp.numerator / denominator * (1 / ns)\n",
    "        \n",
    "        δ_new = δ + np.log(s) - np.log(s_hat)\n",
    "        dist = sum((δ - δ_new)**2)\n",
    "        δ = δ_new\n",
    "        i += 1\n",
    "            \n",
    "    return δ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm(params, p, B, I, X):\n",
    "    α = params[0]\n",
    "    β = params[1]\n",
    "    σ_B = params[2]\n",
    "    σ_I = params[3]\n",
    "    \n",
    "    δ_init = β * X + α * p #Initial δ\n",
    "    \n",
    "    δ = iterate_shares(α, β, σ_I, σ_B, δ_init, v, p, B, I, X)\n",
    "    ξ = δ - β * X - α * p\n",
    "    Q = Z.T @ ξ @ np.linalg.inv(Z.T @ Z) @ Z.T @ ξ\n",
    "    print(Q)\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 14.918472\n",
      "         Iterations: 19\n",
      "         Function evaluations: 282\n",
      "         Gradient evaluations: 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 14.918472227876286\n",
       " hess_inv: array([[ 4.01482068e-02, -9.14117349e-02, -1.67883157e-03,\n",
       "         5.39769344e-02],\n",
       "       [-9.14117349e-02,  4.30387542e-01, -1.00611240e-03,\n",
       "        -1.45398217e-01],\n",
       "       [-1.67883157e-03, -1.00611240e-03,  1.77177704e-04,\n",
       "        -9.66942856e-04],\n",
       "       [ 5.39769344e-02, -1.45398217e-01, -9.66942857e-04,\n",
       "         3.85611674e-01]])\n",
       "      jac: array([ -2.43322492,  -0.56465507, -26.17993426,   0.06863439])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 282\n",
       "      nit: 19\n",
       "     njev: 54\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([ 0.15723809, -2.46938866, -0.00866409,  0.27780061])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.array((α, β, σ_I, σ_B))\n",
    "scipy.optimize.minimize(gmm, params, args=(p, B, I, X), \n",
    "                   options={'disp' : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
